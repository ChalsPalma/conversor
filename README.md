# Conversor de PDF a Embeddings Vectoriales

Una aplicaci√≥n completa para convertir documentos PDF en embeddings vectoriales, permitiendo b√∫squedas sem√°nticas avanzadas y an√°lisis de documentos.

## üöÄ Caracter√≠sticas Principales

- **Extracci√≥n de Texto Robusta**: Utiliza PyMuPDF para extraer texto de PDFs con manejo de errores avanzado
- **Chunking Inteligente**: Divisi√≥n de texto usando LangChain con solapamiento configurable
- **Embeddings de Alta Calidad**: Soporte para m√∫ltiples modelos de Sentence-Transformers
- **Base de Datos Vectorial**: Almacenamiento eficiente con ChromaDB
- **Interfaz Web Intuitiva**: Aplicaci√≥n Streamlit f√°cil de usar
- **B√∫squeda Sem√°ntica**: Consultas en lenguaje natural con resultados relevantes
- **Gesti√≥n de Colecciones**: Organizaci√≥n y administraci√≥n de documentos procesados

## üìã Requisitos del Sistema

- Python 3.8 o superior
- 4GB de RAM m√≠nimo (8GB recomendado)
- 2GB de espacio libre en disco
- Conexi√≥n a internet para descargar modelos

## üõ†Ô∏è Instalaci√≥n

1. **Clonar el repositorio**:
```bash
git clone <repository-url>
cd pdf-to-embeddings
```

2. **Crear entorno virtual**:
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

4. **Verificar instalaci√≥n**:
```bash
python pdf_extractor.py
python text_chunker.py
python embedding_processor.py
```

## üöÄ Uso R√°pido

### Ejecutar la Aplicaci√≥n Web

```bash
streamlit run streamlit_app.py --server.port 8501 --server.address 0.0.0.0
```

Accede a la aplicaci√≥n en: `http://localhost:8501`

### Uso Program√°tico

```python
from pdf_extractor import extract_text_from_pdf
from text_chunker import split_text_into_chunks
from embedding_processor import generate_embeddings_and_store

# Procesar un PDF
text = extract_text_from_pdf("documento.pdf")
chunks = split_text_into_chunks(text, chunk_size=500, chunk_overlap=100)
generate_embeddings_and_store("documento.pdf", collection_name="mi_coleccion")
```

## üìÅ Estructura del Proyecto

```
pdf-to-embeddings/
‚îú‚îÄ‚îÄ pdf_extractor.py          # Extracci√≥n de texto de PDFs
‚îú‚îÄ‚îÄ text_chunker.py           # Divisi√≥n de texto en chunks
‚îú‚îÄ‚îÄ embedding_processor.py    # Generaci√≥n y almacenamiento de embeddings
‚îú‚îÄ‚îÄ streamlit_app.py          # Interfaz web principal
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias del proyecto
‚îú‚îÄ‚îÄ README.md                # Este archivo
‚îî‚îÄ‚îÄ chroma_db/               # Base de datos vectorial (se crea autom√°ticamente)
```

## ‚öôÔ∏è Configuraci√≥n

### Modelos de Embeddings Disponibles

- `all-MiniLM-L6-v2`: R√°pido y eficiente (384 dimensiones)
- `all-mpnet-base-v2`: Alta calidad (768 dimensiones)
- `paraphrase-MiniLM-L6-v2`: Optimizado para par√°frasis
- `distilbert-base-nli-stsb-mean-tokens`: Basado en BERT

### Par√°metros de Chunking

- **Tama√±o del Chunk**: 100-2000 caracteres (recomendado: 500)
- **Solapamiento**: 0-500 caracteres (recomendado: 100)

## üîç Ejemplos de Uso

### B√∫squeda Sem√°ntica

```python
import chromadb
from chromadb.utils import embedding_functions

client = chromadb.PersistentClient(path="./chroma_db")
collection = client.get_collection("mi_coleccion")

results = collection.query(
    query_texts=["inteligencia artificial"],
    n_results=3
)

for doc, distance in zip(results['documents'][0], results['distances'][0]):
    print(f"Similitud: {1-distance:.3f}")
    print(f"Texto: {doc}\n")
```

### Procesamiento por Lotes

```python
import os
from pathlib import Path

pdf_directory = "documentos/"
for pdf_file in Path(pdf_directory).glob("*.pdf"):
    print(f"Procesando: {pdf_file}")
    generate_embeddings_and_store(
        str(pdf_file), 
        collection_name="documentos_lote"
    )
```

## üêõ Soluci√≥n de Problemas

### Error: "No se pudo extraer texto del PDF"
- Verifica que el PDF no est√© protegido con contrase√±a
- Aseg√∫rate de que el archivo no est√© corrupto
- Para PDFs escaneados, considera usar OCR

### Error de memoria con documentos grandes
- Reduce el tama√±o del chunk
- Procesa el documento en secciones
- Aumenta la memoria disponible del sistema

### Modelos no se descargan
- Verifica la conexi√≥n a internet
- Comprueba el espacio disponible en disco
- Reinicia la aplicaci√≥n

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'A√±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

## üôè Agradecimientos

- [PyMuPDF](https://pymupdf.readthedocs.io/) por la extracci√≥n de texto de PDFs
- [LangChain](https://python.langchain.com/) por las herramientas de procesamiento de texto
- [Sentence-Transformers](https://www.sbert.net/) por los modelos de embeddings
- [ChromaDB](https://www.trychroma.com/) por la base de datos vectorial
- [Streamlit](https://streamlit.io/) por el framework de interfaz web

## üìû Soporte

Para preguntas, problemas o sugerencias:
- Abre un issue en GitHub
- Consulta la documentaci√≥n completa en `plan_de_aplicacion.md`

---

**Desarrollado por**: Manus AI  
**Versi√≥n**: 1.0  
**√öltima actualizaci√≥n**: Agosto 2025

